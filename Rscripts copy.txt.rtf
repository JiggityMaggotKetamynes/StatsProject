{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Times-Roman;\f1\froman\fcharset0 Times-Bold;\f2\fmodern\fcharset0 Courier;
\f3\fmodern\fcharset0 Courier-Bold;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww10980\viewh19320\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs24 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \

\f1\b Package importation\
\
\pard\pardeftab720\partightenfactor0

\f0\b0 \cf0 install.packages(c("tidyverse", "readxl", "ggplot2", "dplyr"))\
\
library(readxl)\
\
file_path <- "path_to_your_file/Data.xlsx"  \
df <- read_excel(file_path, sheet = "Sheet 1 - 30457_Assignment_Data")\
\
# Rename the columns appropriately\
colnames(df) <- c("sex", "language", "siblings", "account_num", "story_views",\
                  "day_time_min", "num_follower", "num_post", "effectiveness",\
                  "attractiveness", "private_d")\
\pard\pardeftab720\partightenfactor0

\f1\b \cf0 \
\
A.1.a\
\
Histogram of Siblings
\f0\b0 \
\
ggplot(df %>% filter(!is.na(siblings)), aes(x = siblings)) + \
  geom_bar(color = "black", fill = "skyblue", stat = "count") + \
  labs(title = "Bar Plot of Siblings", x = "Number of Siblings", y = "Frequency") + \
  theme_minimal()\
\
\

\f1\b Histogram of Account Numbers \
\

\f0\b0 # Check the data type of 'account_num'\
str(df$account_num)\
\
# Convert 'account_num' to numeric if necessary\
df$account_num <- as.numeric(df$account_num)\
\
\
ggplot(df %>% filter(!is.na(account_num)), aes(x = account_num)) + geom_histogram(binwidth = 1, color = "black", fill = "skyblue") + labs( title = "Histogram of Account Number", x = "Number of Accounts", y = "Frequency" ) + theme_minimal()\
\

\f1\b Histogram of Story Views\
\

\f0\b0 # Check the data type of 'story_views' and 'account_num'\
str(df$story_views)\
str(df$account_num)\
\
# Convert to numeric if not already\
df$story_views <- as.numeric(df$story_views)\
df$account_num <- as.numeric(df$account_num)\
\
\pard\pardeftab720\partightenfactor0
\cf0 ggplot(df %>% filter(!is.na(story_views)), aes(x = story_views)) + geom_histogram(binwidth = 50, color = "black", fill = "skyblue") + labs( title = "Histogram of Story Views", x = "Number of Story Views", y = "Frequency" ) + theme_minimal()\

\f2\fs26 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f3\b \cf0 Histogram of Day Time in minutes
\f2\b0 \
\
\pard\pardeftab720\partightenfactor0

\f0\fs24 \cf0 \strokec2 # Check the structure of 'story_views' and 'day_time_min'\
str(df$story_views)\
str(df$day_time_min)\
\
# If they are not numeric, convert them to numeric\
df$story_views <- as.numeric(df$story_views)\
df$day_time_min <- as.numeric(df$day_time_min)\
\
ggplot(df %>% filter(!is.na(day_time_min)), aes(x = day_time_min)) + geom_histogram(binwidth = 10, color = "black", fill = "skyblue") + labs( title = "Histogram of Day Time (Minutes)", x = "Average Daily Time (Minutes)", y = "Frequency" ) + theme_minimal()\
\

\f1\b Hist of number of followers 
\f0\b0 \
\
\pard\pardeftab720\partightenfactor0
\cf0 df$num_follower <- as.numeric(df$num_follower)\
ggplot(df %>% filter(!is.na(num_follower)), aes(x = num_follower)) + geom_histogram(binwidth = 50, color = "black", fill = "skyblue") + labs( title = "Histogram of Number of Followers", x = "Number of Followers", y = "Frequency" ) + theme_minimal()\
\

\f1\b Histogram num of post\
\

\f0\b0 # Check the structure of 'num_post'\
str(df$num_post)\
\
# Convert 'num_post' to numeric if necessary\
df$num_post <- as.numeric(df$num_post)\

\f1\b \

\f0\b0 ggplot(df %>% filter(!is.na(num_post)), aes(x = num_post)) + geom_histogram(binwidth = 10, color = "black", fill = "skyblue") + labs( title = "Histogram of Number of Posts", x = "Number of Posts", y = "Frequency" ) + theme_minimal()\
\

\f1\b Hist of attractiveness\
\

\f0\b0 df$attractiveness <- as.numeric(df$attractiveness)\
\
ggplot(df %>% filter(!is.na(attractiveness)), aes(x = attractiveness)) + geom_histogram(binwidth = 1, color = "black", fill = "skyblue") + labs( title = "Histogram of Attractiveness", x = "Attractiveness Rating", y = "Frequency" ) + theme_minimal()
\f1\b \

\f0\b0 \

\f1\b Private account bar Chart - Binary\

\f0\b0 \
df$private_d <- as.numeric(df$private_d)\
\
ggplot(df, aes(x = as.factor(private_d))) +\
  geom_bar(color = "black", fill = "skyblue") +\
  labs(\
    title = "Bar Chart of Private Account Status",\
    x = "Private Account (1 = Yes, 0 = No)",\
    y = "Count"\
  ) +\
  theme_minimal() +\
  theme(axis.title.x = element_text(size = 12), axis.title.y = element_text(size = 12))\
\

\f1\b Bar chart of sex\
\

\f0\b0 ggplot(df, aes(x = sex)) + geom_bar(color = "black", fill = "skyblue") + labs( title = "Bar Chart of Sex", x = "Sex (M = Male, F = Female)", y = "Count" ) + theme_minimal() + theme(axis.title.x = element_text(size = 12), axis.title.y = element_text(size = 12))\
\

\f1\b Bar Chart Lang\
\
\pard\pardeftab720\partightenfactor0

\f0\b0 \cf0 ggplot(df, aes(x = language)) + geom_bar(color = "black", fill = "skyblue") + labs( title = "Bar Chart of Language", x = "Language", y = "Count" ) + theme_minimal() + theme(axis.title.x = element_text(size = 12), axis.title.y = element_text(size = 12))\
\

\f1\b Bar Chart Effectiveness\
\

\f0\b0 ggplot(df, aes(x = effectiveness)) + geom_bar(color = "black", fill = "skyblue") + labs( title = "Bar Chart of Effectiveness", x = "Effectiveness (Agreement with Instagram Effectiveness)", y = "Count" ) + theme_minimal() + theme(axis.title.x = element_text(size = 12), axis.title.y = element_text(size = 12))\
\

\f1\b A.1.b\
\
Quartile Decile Percentile \
\

\f0\b0 # Calculate quartiles, deciles, and percentiles for each numeric column\
numeric_cols <- df %>% select_if(is.numeric)  # Select only numeric columns\
\
# Compute quartiles (Q1, Q2 (median), Q3)\
quartiles <- apply(numeric_cols, 2, function(x) quantile(x, probs = c(0.25, 0.5, 0.75), na.rm = TRUE))\
\
# Compute deciles\
deciles <- apply(numeric_cols, 2, function(x) quantile(x, probs = seq(0.1, 1, by = 0.1), na.rm = TRUE))\
\
# Compute percentiles (1st, 5th, 10th, ..., 95th, 99th)\
percentiles <- apply(numeric_cols, 2, function(x) quantile(x, probs = seq(0.01, 0.99, by = 0.01), na.rm = TRUE))\
\
# Display the results\
list(\
  quartiles = quartiles,\
  deciles = deciles,\
  percentiles = percentiles\
)\
\
\

\f1\b Variance, SD, Mean deviation, quart deviation 
\f0\b0 \
\
# Select only numeric columns\
numeric_cols <- df %>% select_if(is.numeric)\
\
# Calculate variance\
variance <- apply(numeric_cols, 2, function(x) var(x, na.rm = TRUE))\
\
# Calculate standard deviation\
std_dev <- apply(numeric_cols, 2, function(x) sd(x, na.rm = TRUE))\
\
# Calculate mean deviation\
mean_deviation <- apply(numeric_cols, 2, function(x) mean(abs(x - mean(x, na.rm = TRUE)), na.rm = TRUE))\
\
# Calculate quartile deviation (QD = (Q3 - Q1) / 2)\
quartile_deviation <- apply(numeric_cols, 2, function(x) \{\
  Q1 <- quantile(x, 0.25, na.rm = TRUE)\
  Q3 <- quantile(x, 0.75, na.rm = TRUE)\
  (Q3 - Q1) / 2\
\})\
\
# Combine results into a data frame\
results <- data.frame(\
  Variance = variance,\
  Std_Dev = std_dev,\
  Mean_Deviation = mean_deviation,\
  Quartile_Deviation = quartile_deviation\
)\
\
# Display the results\
results\
\
\

\f1\b **A.2** \
\
Outlier Identification\
\
\

\f0\b0 library(ggplot2)\
\
# Identify numeric columns\
numeric_columns <- names(df)[sapply(df, is.numeric)]\
\
# Create boxplots for each numeric variable to visualize outliers\
for (col in numeric_columns) \{\
  # Create boxplot with jittered points for outliers\
  p <- ggplot(df, aes(x = factor(0), y = .data[[col]])) + \
    geom_boxplot(color = "black", fill = "skyblue") +\
    geom_jitter(color = "red", width = 0.2, alpha = 0.5) +  # Red points for outliers\
    labs(title = paste("Boxplot of", col), y = col) +\
    theme_minimal() +\
    theme(axis.title.x = element_blank(), axis.title.y = element_text(size = 12))\
  \
  print(p)  # Explicitly print the plot to ensure it displays\
\}\
\

\f1\b Identifying using IQR\
\

\f0\b0 # Identifying outliers using IQR method for each numeric column\
outliers_list <- list()\
\
for (col in numeric_columns) \{\
  # Calculate Q1, Q3, and IQR\
  Q1 <- quantile(df[[col]], 0.25, na.rm = TRUE)\
  Q3 <- quantile(df[[col]], 0.75, na.rm = TRUE)\
  IQR <- Q3 - Q1\
  lower_bound <- Q1 - 1.5 * IQR\
  upper_bound <- Q3 + 1.5 * IQR\
  \
  # Identify outliers\
  outliers <- df[df[[col]] < lower_bound | df[[col]] > upper_bound, ]\
  \
  # Store outliers in the list\
  outliers_list[[col]] <- outliers\
\}\
\
# Print outliers for each column\
outliers_list\
\

\f1\b Exlclusion\
\

\f0\b0 # Exclude outliers from the dataset for each column\
df_cleaned <- df\
\
for (col in numeric_columns) \{\
  Q1 <- quantile(df_cleaned[[col]], 0.25, na.rm = TRUE)\
  Q3 <- quantile(df_cleaned[[col]], 0.75, na.rm = TRUE)\
  IQR <- Q3 - Q1\
  lower_bound <- Q1 - 1.5 * IQR\
  upper_bound <- Q3 + 1.5 * IQR\
  \
  # Filter out the rows with outliers\
  df_cleaned <- df_cleaned %>%\
    filter(df_cleaned[[col]] >= lower_bound & df_cleaned[[col]] <= upper_bound)\
\}\
\
# Check the cleaned dataset\
head(df_cleaned)\
\

\f1\b A.2:\
\

\f0\b0 #remove rows with NA values: \
\
# Remove rows with any NA values from the dataset\
df_cleaned <- df %>% filter(complete.cases(df))\
\
# Check the first few rows of the cleaned dataset\
head(df_cleaned)\
\
# Check the number of rows before and after cleaning\
cat("Original number of rows:", nrow(df), "\\n")\
cat("Cleaned number of rows:", nrow(df_cleaned), "\\n")\
\
# Remove Outliers\
\
# Identify numeric columns in the dataset\
numeric_columns <- names(df_cleaned)[sapply(df_cleaned, is.numeric)]\
\
# Function to remove outliers based on IQR method\
remove_outliers <- function(data) \{\
  for (col in numeric_columns) \{\
    # Calculate Q1, Q3, and IQR for each numeric column\
    Q1 <- quantile(data[[col]], 0.25, na.rm = TRUE)\
    Q3 <- quantile(data[[col]], 0.75, na.rm = TRUE)\
    IQR <- Q3 - Q1\
    \
    # Calculate lower and upper bounds for outliers\
    lower_bound <- Q1 - 1.5 * IQR\
    upper_bound <- Q3 + 1.5 * IQR\
    \
    # Filter out rows where the column value is an outlier\
    data <- data %>% filter(data[[col]] >= lower_bound & data[[col]] <= upper_bound)\
  \}\
  return(data)\
\}\
\
# Apply the function to remove outliers\
df_cleaned_no_outliers <- remove_outliers(df_cleaned)\
\
# Check the first few rows after removing outliers\
head(df_cleaned_no_outliers)\
\
# Check the number of rows before and after removing outliers\
cat("Rows before removing outliers:", nrow(df_cleaned), "\\n")\
cat("Rows after removing outliers:", nrow(df_cleaned_no_outliers), "\\n")\
\

\f1\b B.1 \
\

\f0\b0 # Check the unique values in the 'story_views' column to understand what data we have\
unique(df_cleaned$story_views)\
\
# Check the proportion of missing data in the 'story_views' column\
missing_data_proportion <- sum(is.na(df_cleaned$story_views)) / length(df_cleaned$story_views)\
cat("Proportion of missing data in 'story_views':", round(missing_data_proportion * 100, 2), "%\\n")\
\
# Check for non-numeric entries in the 'story_views' column\
non_numeric_entries <- df_cleaned$story_views[!grepl("^[0-9.]+$", df_cleaned$story_views)]\
cat("Non-numeric entries in 'story_views':", non_numeric_entries, "\\n")\

\f1\b \
\

\f0\b0 # Remove any NA values from 'story_views' before calculation\
story_views_clean <- df_cleaned$story_views[!is.na(df_cleaned$story_views)]\
\
# Compute the mean and standard deviation for story_views (after removing NAs)\
mean_story_views <- mean(story_views_clean)\
sd_story_views <- sd(story_views_clean)\
n <- length(story_views_clean)  # Sample size\
\
# Standard Error (SE) of the mean\
se_story_views <- sd_story_views / sqrt(n)\
\
# t-critical value for 95% confidence interval (two-tailed)\
t_critical <- qt(0.975, df = n - 1)  # 0.975 corresponds to a 95% CI\
\
# Confidence Interval calculation\
ci_lower <- mean_story_views - t_critical * se_story_views\
ci_upper <- mean_story_views + t_critical * se_story_views\
\
# Output the results\
cat("95% Confidence Interval for Story Views: [", round(ci_lower, 2), ", ", round(ci_upper, 2), "]\\n")\
\

\f1\b B.1.a For siblings = 0, CI 95%\
\

\f0\b0 # Filter the data for siblings = 0\
data_siblings_0 <- df %>% filter(siblings == 0)\
\
# Calculate the mean and standard deviation for 'story_views'\
mean_story_views <- mean(data_siblings_0$story_views, na.rm = TRUE)\
sd_story_views <- sd(data_siblings_0$story_views, na.rm = TRUE)\
\
# Sample size\
n <- length(data_siblings_0$story_views)\
\
# Calculate the standard error\
se_story_views <- sd_story_views / sqrt(n)\
\
# Calculate the 95% confidence interval\
z_score <- 1.96  # for 95% confidence level\
ci_lower <- mean_story_views - z_score * se_story_views\
ci_upper <- mean_story_views + z_score * se_story_views\
\
# Display the results\
ci_lower\
ci_upper\
\
\

\f1\b B.2\
\

\f0\b0 # Remove any non-numeric entries from 'num_follower' (e.g., if there are any invalid values like 'story_views')\
df_cleaned_no_outliers$num_follower <- as.numeric(gsub("[^0-9.-]", "", df_cleaned_no_outliers$num_follower))\
\
# Remove any rows where 'num_follower' is still NA after conversion\
df_cleaned_no_outliers <- df_cleaned_no_outliers[!is.na(df_cleaned_no_outliers$num_follower), ]\
\
# Compute the mean and standard deviation for num_follower\
mean_num_follower <- mean(df_cleaned_no_outliers$num_follower)\
sd_num_follower <- sd(df_cleaned_no_outliers$num_follower)\
n <- length(df_cleaned_no_outliers$num_follower)  # Sample size\
\
# Standard Error (SE) of the mean\
se_num_follower <- sd_num_follower / sqrt(n)\
\
# t-critical value for 99% confidence interval (two-tailed)\
t_critical <- qt(0.995, df = n - 1)  # 0.995 corresponds to a 99% CI\
\
# Confidence Interval calculation\
ci_lower <- mean_num_follower - t_critical * se_num_follower\
ci_upper <- mean_num_follower + t_critical * se_num_follower\
\
# Output the results\
cat("99% Confidence Interval for Number of Followers: [", round(ci_lower, 2), ", ", round(ci_upper, 2), "]\\n")\
\

\f1\b B.2.a Filter the data for men and women\
\

\f0\b0 \
data_men <- df %>% filter(sex == "M")\
data_women <- df %>% filter(sex == "F")\
\
# Calculate the mean and standard deviation for 'num_follower' for men\
mean_num_follower_men <- mean(data_men$num_follower, na.rm = TRUE)\
sd_num_follower_men <- sd(data_men$num_follower, na.rm = TRUE)\
n_men <- length(data_men$num_follower)\
\
# Calculate the standard error for men\
se_num_follower_men <- sd_num_follower_men / sqrt(n_men)\
\
# Calculate the 99% confidence interval for men\
z_score <- 2.576  # For 99% confidence level\
ci_lower_men <- mean_num_follower_men - z_score * se_num_follower_men\
ci_upper_men <- mean_num_follower_men + z_score * se_num_follower_men\
\
# Print the 99% confidence interval for men\
cat("99% Confidence Interval for Men:", ci_lower_men, "to", ci_upper_men, "\\n")\
\
# Calculate the mean and standard deviation for 'num_follower' for women\
mean_num_follower_women <- mean(data_women$num_follower, na.rm = TRUE)\
sd_num_follower_women <- sd(data_women$num_follower, na.rm = TRUE)\
n_women <- length(data_women$num_follower)\
\
# Calculate the standard error for women\
se_num_follower_women <- sd_num_follower_women / sqrt(n_women)\
\
# Calculate the 99% confidence interval for women\
ci_lower_women <- mean_num_follower_women - z_score * se_num_follower_women\
ci_upper_women <- mean_num_follower_women + z_score * se_num_follower_women\
\
# Print the 99% confidence interval for women\
cat("99% Confidence Interval for Women:", ci_lower_women, "to", ci_upper_women, "\\n")\
\
\

\f1\b B.3\
\

\f0\b0 # Calculate the proportion of accounts in Italian\
total_accounts <- nrow(df_cleaned_no_outliers)  # Total number of accounts\
italian_accounts <- sum(df_cleaned_no_outliers$language == "Italian", na.rm = TRUE)  # Number of Italian accounts\
p_hat <- italian_accounts / total_accounts  # Proportion of Italian accounts\
\
# Sample size (n)\
n <- total_accounts\
\
# Z-critical value for 90% confidence interval (two-tailed)\
z_critical <- qnorm(0.95)  # 0.95 corresponds to a 90% CI\
\
# Standard Error (SE) for the proportion\
se_p_hat <- sqrt((p_hat * (1 - p_hat)) / n)\
\
# Confidence Interval calculation\
ci_lower <- p_hat - z_critical * se_p_hat\
ci_upper <- p_hat + z_critical * se_p_hat\
\
# Output the results\
cat("90% Confidence Interval for the Proportion of Accounts in Italian: [", round(ci_lower, 4), ", ", round(ci_upper, 4), "]\\n")\

\f1\b \
C.1 \
\
Answer 1: \
\

\f0\b0 # Split the data into men and women based on the 'sex' column\
men_followers <- df_cleaned_no_outliers[df_cleaned_no_outliers$sex == "M", "num_follower"]\
women_followers <- df_cleaned_no_outliers[df_cleaned_no_outliers$sex == "F", "num_follower"]\
\
# Perform a two-sample t-test\
t_test_result <- t.test(men_followers, women_followers)\
\
# Output the t-test result\
cat("Two-sample t-test result:\\n")\
print(t_test_result)\
\
# Comment on the results at different significance levels\
alpha_1 <- 0.01  # Significance level for 1%\
alpha_2 <- 0.05  # Significance level for 5%\
alpha_3 <- 0.10  # Significance level for 10%\
\
# Comment at different significance levels\
if(t_test_result$p.value < alpha_1) \{\
  cat("At significance level 0.01, we reject the null hypothesis (significant difference).\\n")\
\} else \{\
  cat("At significance level 0.01, we fail to reject the null hypothesis (no significant difference).\\n")\
\}\
\
if(t_test_result$p.value < alpha_2) \{\
  cat("At significance level 0.05, we reject the null hypothesis (significant difference).\\n")\
\} else \{\
  cat("At significance level 0.05, we fail to reject the null hypothesis (no significant difference).\\n")\
\}\
\
if(t_test_result$p.value < alpha_3) \{\
  cat("At significance level 0.10, we reject the null hypothesis (significant difference).\\n")\
\} else \{\
  cat("At significance level 0.10, we fail to reject the null hypothesis (no significant difference).\\n")\
\}\
\
# Compare with results from B.2 (confidence interval for num_follower)\
# You can check if the CI from B.2 shows significant overlap or not\
cat("Comparing with B.2 Confidence Interval (99%): [", round(ci_lower, 2), ", ", round(ci_upper, 2), "]\\n")\
\

\f1\b Also works: \
\

\f0\b0 # Filter the data for men and women\
data_men <- df %>% filter(sex == "M")\
data_women <- df %>% filter(sex == "F")\
\
# Perform the two-sample t-test for 'num_follower' between men and women\
t_test_result <- t.test(data_men$num_follower, data_women$num_follower, \
                        alternative = "two.sided", var.equal = TRUE)\
\
# Display the t-test result\
t_test_result\
\
# Get the p-value from the t-test result\
p_value <- t_test_result$p.value\
\
# Interpret the results for different significance levels\
alpha_values <- c(0.01, 0.05, 0.10)\
\
# Print the result for each significance level\
for (alpha in alpha_values) \{\
  cat("\\nFor alpha =", alpha, ":\\n")\
  if (p_value < alpha) \{\
    cat("Reject the null hypothesis. There is a significant difference in the number of followers between men and women.\\n")\
  \} else \{\
    cat("Fail to reject the null hypothesis. There is no significant difference in the number of followers between men and women.\\n")\
  \}\
\}\
\
\

\f1\b C.2 \
\

\f0\b0 # Split the data into private and public university students based on the 'private_d' column\
private_students_views <- df_cleaned_no_outliers[df_cleaned_no_outliers$private_d == 1, "story_views"]\
public_students_views <- df_cleaned_no_outliers[df_cleaned_no_outliers$private_d == 0, "story_views"]\
\
# Perform a two-sample t-test\
t_test_result <- t.test(private_students_views, public_students_views)\
\
# Output the t-test result\
cat("Two-sample t-test result for 'story_views' between private and public students:\\n")\
print(t_test_result)\
\
# Comment on the results using the p-value\
if(t_test_result$p.value < 0.01) \{\
  cat("At significance level 0.01, we reject the null hypothesis (significant difference).\\n")\
\} else \{\
  cat("At significance level 0.01, we fail to reject the null hypothesis (no significant difference).\\n")\
\}\
\
if(t_test_result$p.value < 0.05) \{\
  cat("At significance level 0.05, we reject the null hypothesis (significant difference).\\n")\
\} else \{\
  cat("At significance level 0.05, we fail to reject the null hypothesis (no significant difference).\\n")\
\}\
\
if(t_test_result$p.value < 0.10) \{\
  cat("At significance level 0.10, we reject the null hypothesis (significant difference).\\n")\
\} else \{\
  cat("At significance level 0.10, we fail to reject the null hypothesis (no significant difference).\\n")\
\}\
\
\

\f1\b C.3\
\

\f0\b0 # Convert 'day_time_min' to numeric and remove any non-numeric values (e.g., column name or characters)\
df_cleaned_no_outliers$day_time_min <- as.numeric(as.character(df_cleaned_no_outliers$day_time_min))\
\
# Remove rows where 'day_time_min' is NA or non-numeric\
df_cleaned_no_outliers <- df_cleaned_no_outliers[!is.na(df_cleaned_no_outliers$day_time_min), ]\
\
# Split the data into English and Italian speakers based on the 'language' column\
english_speakers_time <- df_cleaned_no_outliers[df_cleaned_no_outliers$language == "English", "day_time_min"]\
italian_speakers_time <- df_cleaned_no_outliers[df_cleaned_no_outliers$language == "Italian", "day_time_min"]\
\
# Remove any NA values from the two groups\
english_speakers_time <- english_speakers_time[!is.na(english_speakers_time)]\
italian_speakers_time <- italian_speakers_time[!is.na(italian_speakers_time)]\
\
# Perform a two-sample t-test\
t_test_result <- t.test(english_speakers_time, italian_speakers_time)\
\
# Output the t-test result\
cat("Two-sample t-test result for 'day_time_min' between English and Italian speakers:\\n")\
print(t_test_result)\
\
# Comment on the results using the p-value (significance level \uc0\u945  = 0.01)\
if(t_test_result$p.value < 0.01) \{\
  cat("At significance level 0.01, we reject the null hypothesis (significant difference).\\n")\
\} else \{\
  cat("At significance level 0.01, we fail to reject the null hypothesis (no significant difference).\\n")\
\}\
\

\f1\b D.1 \
\

\f0\b0 install.packages("lmtest")\
library(lmtest
\f1\b )\
\
\
\pard\pardeftab720\partightenfactor0

\f0\b0 \cf0 \outl0\strokewidth0 # Run the linear regression model: 'story_views' as dependent variable and 'num_follower' as independent variable\
lm_model <- lm(story_views ~ num_follower, data = df_cleaned_no_outliers)\
\
# Output the summary of the regression model\
cat("Linear Regression Model Summary:\\n")\
summary(lm_model)\
\
# Check the goodness of fit\
cat("\\nGoodness of Fit: R-squared = ", summary(lm_model)$r.squared, "\\n")\
cat("p-value for the model (num_follower): ", summary(lm_model)$coefficients[2, 4], "\\n")\
\
# Plot the residuals to check for linearity and homoscedasticity\
par(mfrow = c(1, 2))  # Set up a 1x2 plot layout\
\
# Residuals vs Fitted Plot (Check for homoscedasticity and linearity)\
plot(lm_model$fitted.values, lm_model$residuals, \
     main = "Residuals vs Fitted", \
     xlab = "Fitted values", ylab = "Residuals")\
abline(h = 0, col = "red")  # Add a horizontal line at 0\
\
# Normal Q-Q Plot (Check for normality of residuals)\
qqnorm(lm_model$residuals, main = "Normal Q-Q Plot")\
qqline(lm_model$residuals, col = "red")  # Add the reference line\
\
# Reset plot layout\
par(mfrow = c(1, 1))\
\
# Check for normality of residuals using Shapiro-Wilk test\
shapiro_test <- shapiro.test(lm_model$residuals)\
cat("Shapiro-Wilk Normality Test p-value: ", shapiro_test$p.value, "\\n")\
\
# Check for homoscedasticity using Breusch-Pagan test\
bp_test <- bptest(lm_model)\
cat("Breusch-Pagan Test p-value: ", bp_test$p.value, "\\n")\
\pard\pardeftab720\partightenfactor0
\cf0 \outl0\strokewidth0 \strokec2 \
\

\f1\b D.2 \

\f0\b0 \
# Run the linear regression model with additional independent variables\
lm_model_D2 <- lm(story_views ~ num_follower + sex + account_num + num_post + day_time_min, data = df_cleaned_no_outliers)\
\
# Output the summary of the regression model\
cat("Linear Regression Model Summary:\\n")\
summary(lm_model_D2)\
\
# Check the goodness of fit\
cat("\\nGoodness of Fit: R-squared = ", summary(lm_model_D2)$r.squared, "\\n")\
cat("p-value for the model (num_follower): ", summary(lm_model_D2)$coefficients[2, 4], "\\n")\
\
# Plot the residuals to check for linearity and homoscedasticity\
par(mfrow = c(1, 2))  # Set up a 1x2 plot layout\
\
# Residuals vs Fitted Plot (Check for homoscedasticity and linearity)\
plot(lm_model_D2$fitted.values, lm_model_D2$residuals, \
     main = "Residuals vs Fitted", \
     xlab = "Fitted values", ylab = "Residuals")\
abline(h = 0, col = "red")  # Add a horizontal line at 0\
\
# Normal Q-Q Plot (Check for normality of residuals)\
qqnorm(lm_model_D2$residuals, main = "Normal Q-Q Plot")\
qqline(lm_model_D2$residuals, col = "red")  # Add the reference line\
\
# Reset plot layout\
par(mfrow = c(1, 1))\
\
# Check for normality of residuals using Shapiro-Wilk test\
shapiro_test <- shapiro.test(lm_model_D2$residuals)\
cat("Shapiro-Wilk Normality Test p-value: ", shapiro_test$p.value, "\\n")\
\
# Check for homoscedasticity using Breusch-Pagan test\
bp_test <- bptest(lm_model_D2)\
cat("Breusch-Pagan Test p-value: ", bp_test$p.value, "\\n")\
\
\

\f1\b E.1 \
\

\f0\b0 # Step 1: Subset the data for females (sex == "F")\
data_females <- df_cleaned_no_outliers %>% filter(sex == "F")\
\
# Step 2: Calculate the median for the relevant variables\
median_values <- data_females %>%\
  summarise(\
    median_num_follower = median(num_follower, na.rm = TRUE),\
    median_account_num = median(account_num, na.rm = TRUE),\
    median_num_post = median(num_post, na.rm = TRUE),\
    median_day_time_min = median(day_time_min, na.rm = TRUE)\
  )\
\
# Step 3: Create a data frame for the female median account\
female_median_account <- data.frame(\
  num_follower = median_values$median_num_follower,\
  sex = "F",  # Gender is Female\
  account_num = median_values$median_account_num,\
  num_post = median_values$median_num_post,\
  day_time_min = median_values$median_day_time_min\
)\
\
# Step 4: Use the model from D.2 to predict the number of views for the female median account\
predicted_views <- predict(lm_model_D2, newdata = female_median_account)\
\
# Output the predicted number of views\
cat("Predicted number of views for the female median account:", predicted_views, "\\n")\
\
\

\f1\b E.2 \
\

\f0\b0 # Step 1: Use the model from D.2 to predict the number of views for the female median account\
prediction_with_interval <- predict(lm_model_D2, newdata = female_median_account, interval = "confidence", level = 0.95)\
\
# Step 2: Output the predicted value and the 95% confidence interval\
cat("Predicted number of views for the female median account: ", prediction_with_interval[1], "\\n")\
cat("95% Confidence Interval for the prediction: [", prediction_with_interval[2], ", ", prediction_with_interval[3], "]\\n")\

\f1\b \
\
\
F.1 \
\

\f0\b0 # Ensure the target variable 'private_d' is binary (0 or 1)\
df_cleaned_no_outliers$private_d <- as.factor(df_cleaned_no_outliers$private_d)\
\
# Subset the relevant features and target variable\
logistic_data <- df_cleaned_no_outliers[, c("num_follower", "num_post", "story_views", "private_d")]\
\
# Remove rows with missing values\
logistic_data_cleaned <- logistic_data[complete.cases(logistic_data), ]\
\
# Run the logistic regression model: 'private_d' as the dependent variable, and 'num_follower', 'num_post', 'story_views' as independent variables\
logistic_model <- glm(private_d ~ num_follower + num_post + story_views, data = logistic_data_cleaned, family = "binomial")\
\
# Output the summary of the logistic regression model\
cat("Logistic Regression Model Summary:\\n")\
summary(logistic_model)\
\
# Model's goodness of fit\
cat("\\nAIC (Akaike Information Criterion): ", AIC(logistic_model), "\\n")\

\f1\b \
\

\f0\b0 \
\
\
}